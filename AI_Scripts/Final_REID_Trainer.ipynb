{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Juypter labs notebook provides trainging and evaluation of a REID model\n",
    "# that will be used to extract features from images and will work as part of the \n",
    "# multi-object trakcign algorithm from Boxmot repository\n",
    "# The model is based on the ResNet50 architecture and is trained on the Market1501 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-24T22:07:34.926433Z",
     "iopub.status.busy": "2025-04-24T22:07:34.925923Z",
     "iopub.status.idle": "2025-04-24T22:08:29.028294Z",
     "shell.execute_reply": "2025-04-24T22:08:29.027620Z",
     "shell.execute_reply.started": "2025-04-24T22:07:34.926409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# REID Training Repo\n",
    "!pip install git+https://github.com/KaiyangZhou/deep-person-reid.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T22:08:29.029847Z",
     "iopub.status.busy": "2025-04-24T22:08:29.029581Z",
     "iopub.status.idle": "2025-04-24T22:08:35.824114Z",
     "shell.execute_reply": "2025-04-24T22:08:35.823498Z",
     "shell.execute_reply.started": "2025-04-24T22:08:29.029825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import and Dataset Setup\n",
    "import os\n",
    "import torch\n",
    "import torchreid\n",
    "from torch import optim\n",
    "from torchreid import data, models, utils, engine\n",
    "from torchreid.data import ImageDataset\n",
    "import torch.nn as nn\n",
    "\n",
    "utils.set_random_seed(42)\n",
    "\n",
    "DATA_DIR = '/kaggle/input/reid4-24-04/REID4_24_04'\n",
    "OUTPUT_DIR = '/kaggle/working/outputFinal5'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T22:08:35.825285Z",
     "iopub.status.busy": "2025-04-24T22:08:35.824829Z",
     "iopub.status.idle": "2025-04-24T22:08:35.835180Z",
     "shell.execute_reply": "2025-04-24T22:08:35.834510Z",
     "shell.execute_reply.started": "2025-04-24T22:08:35.825265Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom dataset Preoprocessing\n",
    "\n",
    "# This sectiom will include loading of custom dataset class for using the Market1501 formatting\n",
    "# With additionally relabeling of the PIDs and CAMIDs\n",
    "\n",
    "# Define the custom dataset\n",
    "class customMarketData(ImageDataset):\n",
    "    def __init__(self, root='', **kwargs):\n",
    "        self.dataset_dir = root\n",
    "        train_dir = os.path.join(self.dataset_dir, 'bounding_box_train')\n",
    "        query_dir = os.path.join(self.dataset_dir, 'query')\n",
    "        gallery_dir = os.path.join(self.dataset_dir, 'bounding_box_test')\n",
    "\n",
    "        # Process directories\n",
    "        train = self._process_dir(train_dir, relabel=True)\n",
    "        query = self._process_dir(query_dir, relabel=False, force_camid=0)\n",
    "        gallery = self._process_dir(gallery_dir, relabel=False, force_camid=1)\n",
    "\n",
    "        # Print PID info\n",
    "        query_pids = sorted(set([pid for _, pid, _ in query]))\n",
    "        gallery_pids = sorted(set([pid for _, pid, _ in gallery]))\n",
    "        print(f\"[INFO] Query PIDs    ({len(query_pids)}): {query_pids}\")\n",
    "        print(f\"[INFO] Gallery PIDs  ({len(gallery_pids)}): {gallery_pids}\")\n",
    "\n",
    "        super().__init__(train, query, gallery, **kwargs)\n",
    "\n",
    "    def _process_dir(self, dir_path, relabel=False, force_camid=None):\n",
    "        img_paths = sorted([\n",
    "            os.path.join(dir_path, fname)\n",
    "            for fname in os.listdir(dir_path)\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "        ])\n",
    "\n",
    "        pid_container = set()\n",
    "        for img_path in img_paths:\n",
    "            pid = int(os.path.basename(img_path).split('_')[0])\n",
    "            pid_container.add(pid)\n",
    "\n",
    "        pid2label = {pid: idx for idx, pid in enumerate(sorted(pid_container))}\n",
    "\n",
    "        # CamID Forcing Logic\n",
    "        # Section needed for the Market1501 Dataset Format\n",
    "        # Comment out only if a different camera is actually used on the same object, otherwise keep \n",
    "        # If my \"REIDMarketCreatorClass\" script was used to create Data\n",
    "        data = []\n",
    "        for img_path in img_paths:\n",
    "            fname = os.path.basename(img_path)\n",
    "            pid = int(fname.split('_')[0])\n",
    "            camid = int(fname.split('_')[1][1])\n",
    "            if force_camid is not None:\n",
    "                camid = force_camid\n",
    "            if relabel:\n",
    "                pid = pid2label[pid]\n",
    "            data.append((img_path, pid, camid))\n",
    "        return data\n",
    "        \n",
    "print(\"Dataset Preprocessing Class Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T22:08:35.836816Z",
     "iopub.status.busy": "2025-04-24T22:08:35.836612Z",
     "iopub.status.idle": "2025-04-24T22:08:36.210817Z",
     "shell.execute_reply": "2025-04-24T22:08:36.210105Z",
     "shell.execute_reply.started": "2025-04-24T22:08:35.836801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data loader and register\n",
    "# Register the dataset under a new unique name\n",
    "data.register_image_dataset('Name_of_dataset', customMarketData)\n",
    "\n",
    "# Initialize the ImageDataManager using your registered dataset\n",
    "datamanager = data.ImageDataManager(\n",
    "    root=DATA_DIR,\n",
    "    sources='Name_of_dataset',\n",
    "    targets='Name_of_dataset',\n",
    "    height=256,\n",
    "    width=128,\n",
    "    batch_size_train=128,\n",
    "    train_sampler='RandomIdentitySampler',\n",
    "    num_instances=8,\n",
    "    transforms='random_flip+random_crop+color_jitter+random_erase+normalize',\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "print(\"Data loader complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T22:08:36.212433Z",
     "iopub.status.busy": "2025-04-24T22:08:36.211617Z",
     "iopub.status.idle": "2025-04-24T23:30:31.380995Z",
     "shell.execute_reply": "2025-04-24T23:30:31.380254Z",
     "shell.execute_reply.started": "2025-04-24T22:08:36.212414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model builder\n",
    "# Builds the ReID model using the OSNet-AIN architecture (osnet_ain_x1_0), with software loss functioand and pretrained weights\n",
    "\n",
    "model = models.build_model(\n",
    "    name='osnet_ain_x1_0',\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss='softmax',\n",
    "    pretrained=True,\n",
    "    use_gpu=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n",
    "\n",
    "# Optimizer & scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "# Trainer\n",
    "trainer = engine.ImageSoftmaxEngine(\n",
    "    datamanager=datamanager,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    label_smooth=True\n",
    ")\n",
    "\n",
    "# Training Loop\n",
    "trainer.run(\n",
    "    save_dir=OUTPUT_DIR,\n",
    "    max_epoch=100,\n",
    "    eval_freq=10,\n",
    "    print_freq=50,\n",
    "    start_eval=10,\n",
    "    fixbase_epoch=0,\n",
    "    open_layers=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T23:30:31.382689Z",
     "iopub.status.busy": "2025-04-24T23:30:31.382392Z",
     "iopub.status.idle": "2025-04-24T23:30:34.888164Z",
     "shell.execute_reply": "2025-04-24T23:30:34.887371Z",
     "shell.execute_reply.started": "2025-04-24T23:30:31.382657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.eval()\n",
    "dummy_input = torch.zeros(1, 3, 256, 128).cuda() if torch.cuda.is_available() else torch.zeros(1, 3, 256, 128)\n",
    "traced_model = torch.jit.trace(model, dummy_input)\n",
    "traced_model.save('./dir/to_____.pt')\n",
    "print(\"TorchScript model saved as ....\")\n",
    "\n",
    "# Save state_dict for BoxMOT\n",
    "torch.save(model.state_dict(), './dir/to_____.pt')\n",
    "print(\"PyTorch model state_dict saved as ...\")\n",
    "\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T23:30:34.890155Z",
     "iopub.status.busy": "2025-04-24T23:30:34.889111Z",
     "iopub.status.idle": "2025-04-24T23:30:34.894504Z",
     "shell.execute_reply": "2025-04-24T23:30:34.893888Z",
     "shell.execute_reply.started": "2025-04-24T23:30:34.890134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Section to check for files existance\n",
    "# Check for files\n",
    "for root, dirs, files in os.walk('/kaggle/working'):\n",
    "    for file in files:\n",
    "        if file.endswith(('.pt', '.pth')):\n",
    "            print(\"Found:\", os.path.join(root, file))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7204103,
     "sourceId": 11492318,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7241902,
     "sourceId": 11547957,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
